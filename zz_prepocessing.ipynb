{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import gzip\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "def parseInstruction(instruction : str) -> list:\n",
    "    opcode = ''\n",
    "    args = []\n",
    "\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    instParts = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')\n",
    "    meta = ''\n",
    "\n",
    "    if len(instParts) > 1:\n",
    "        meta      = instParts[-1]\n",
    "        instParts = instParts[0]\n",
    "        meta = meta.split('@')[0]\n",
    "    else:\n",
    "        instParts = instParts[0]    \n",
    "    instParts = instParts.split(' ')\n",
    "    #instParts = [item for item in instParts if item != '']\n",
    "    opcode = instParts[0]\n",
    "    args = []\n",
    "\n",
    "    # TODO proto meta \n",
    "    if len(instParts) > 1:\n",
    "        args = ' '.join(instParts[1:]).split(', ')\n",
    "        if args[-1][0] == '\"':\n",
    "            args[-1] = 'string'\n",
    "            \n",
    "        elif args[-1][0] == '#':\n",
    "            args[-1] = args[-1].split()[0][1:]\n",
    "            \n",
    "        elif args[-1][0] == '0':\n",
    "            args[-1] = 'hex'\n",
    "            \n",
    "        elif meta == 'field':\n",
    "            fields = args[-1].split(':')\n",
    "            if len(fields) > 1:\n",
    "                args[-1] = fields[1].replace(';', '')\n",
    "                if args[-1][0] != 'L' or (len(args[-1].split('/')[0]) == 2):\n",
    "                    args[-1] = 'field'\n",
    "            else:\n",
    "                args[-1] = 'field'\n",
    "                \n",
    "        elif meta == 'type':\n",
    "            args[-1] = args[-1].replace(';', '')\n",
    "            if (args[-1][0] != 'L') or (len(args[-1].split('/')[0]) == 2):\n",
    "                args[-1] = 'type'\n",
    "                \n",
    "        elif meta == 'method':\n",
    "            args[-1] = args[-1].replace(';.', '->')\n",
    "            methodParts = args[-1].split(':')\n",
    "            methodCall = methodParts[0]\n",
    "            if len(methodCall.split('/')[0]) == 2:\n",
    "                methodCall = 'class.local'\n",
    "            if len(methodParts) > 1:\n",
    "                methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "                methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "            else:\n",
    "                methodArgs = []\n",
    "\n",
    "            mtdSplit = methodCall.split('->')\n",
    "            if len(mtdSplit) > 1:\n",
    "                methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "\n",
    "            args[-1] = methodCall\n",
    "\n",
    "            args.extend(methodArgs)\n",
    "        else:\n",
    "            args = [item for item in args if len(item) > 1 and item[0] == 'v']\n",
    "            \n",
    "    return ' '.join([opcode] + args)\n",
    "\n",
    "def parseMethodCallArguments(instruction : str) -> list:\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    method = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')[0].split(' ')[-1]\n",
    "\n",
    "    method = method.replace(';.', '->')\n",
    "    methodParts = method.split(':')\n",
    "    methodCall = methodParts[0]\n",
    "    if len(methodCall.split('/')[0]) == 2:\n",
    "        methodCall = 'class.local'\n",
    "        \n",
    "    if len(methodParts) > 1:\n",
    "        methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "        methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "    else:\n",
    "        methodArgs = []\n",
    "        \n",
    "    mtdSplit = methodCall.split('->')\n",
    "    if len(mtdSplit) > 1:\n",
    "        methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "                \n",
    "    method = methodCall\n",
    "\n",
    "    return ' '.join([method] + methodArgs)\n",
    "\n",
    "def parseMethodCall(instruction : str) -> str:\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    method = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')[0].split(' ')[-1]\n",
    "\n",
    "    method = method.replace(';.', '->')\n",
    "    methodParts = method.split(':')\n",
    "    methodCall = methodParts[0]\n",
    "    if len(methodCall.split('/')[0]) == 2:\n",
    "        methodCall = 'class.local'\n",
    "        \n",
    "    if len(methodParts) > 1:\n",
    "        methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "        methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "    else:\n",
    "        methodArgs = []\n",
    "        \n",
    "    mtdSplit = methodCall.split('->')\n",
    "    if len(mtdSplit) > 1:\n",
    "        methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "        \n",
    "    method = methodCall\n",
    "\n",
    "    return methodCall\n",
    "\n",
    "def parseFieldAccess(instruction : str) -> str:\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    field = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')[0].split(' ,')[-1]\n",
    "\n",
    "    fields = field.split(':')\n",
    "\n",
    "    if len(fields) > 1:\n",
    "        fields = fields[1].replace(';', '')\n",
    "        if field[0] != 'L' or (len(args[-1].split('/')[0]) == 2):\n",
    "            field = 'field'\n",
    "    else:\n",
    "        field = 'field'\n",
    "\n",
    "    return field\n",
    "\n",
    "def parseDex(FileName : str) -> list:\n",
    "    global outputRoot\n",
    "    global inputRoot\n",
    "    \n",
    "    outputFilePath = outputRoot + FileName\n",
    "    inputFilePath  = inputRoot  + FileName\n",
    "\n",
    "    dex = subprocess.run(['dexdump', '-d', inputFilePath], stdout=subprocess.PIPE).stdout.decode(encoding=\"ISO-8859-1\")\n",
    "    condidatClasses = re.split(\"Class descriptor  : '\", dex)[1:]\n",
    "\n",
    "    collectedMethods = []\n",
    "\n",
    "    for currentClass in condidatClasses:\n",
    "        className = currentClass.split('\\n')[0][1:-2]\n",
    "        currentCondidatMethods = re.split('    #\\d', currentClass)\n",
    "        for method in currentCondidatMethods:\n",
    "            if method != '':\n",
    "                Instructions = [item for item in method.split('\\n') if '|' in item]\n",
    "                if len(Instructions) != 0:\n",
    "                    methodMeta = Instructions[0].split()[-1]\n",
    "                    Instructions = Instructions[1:]\n",
    "\n",
    "                    functionOpcodes            = ''.join([re.split('\\: |\\|', instruction)[1].strip()  for instruction in Instructions])\n",
    "                    functionOpcodes            = re.sub('[^a-f0-9]+', '', functionOpcodes)\n",
    "                    functionOpcodes            = np.array([int(functionOpcodes[idx:idx+2], 16) for idx in range(int(len(functionOpcodes) / 2))], dtype='uint8')\n",
    "                    \n",
    "                    functionInstructions       = ' '.join([parseInstruction(line)         for line in Instructions])\n",
    "                    functionMethodCallsArgs    = ' '.join([parseMethodCallArguments(line) for line in Instructions if ('method@' in line)])\n",
    "                    functionMethodCalls        = ' '.join([parseMethodCall(line)          for line in Instructions if ('method@' in line)])\n",
    "                    #functionFieldAccess        = ' '.join([parseFieldAccess(line)         for line in Instructions if ('field@' in line)])\n",
    "\n",
    "                    collectedMethods.append((className, methodMeta, functionOpcodes, functionMethodCallsArgs, functionMethodCalls, functionInstructions)) #, Instructions))\n",
    "\n",
    "    if len(collectedMethods) > 1:\n",
    "        colNames = ['className', 'methodMeta', 'functionOpcodes', \n",
    "                    'functionMethodCallsArgs', 'functionMethodCalls', \n",
    "                     'functionInstructions'] #, 'Instructions']\n",
    "        df = pd.DataFrame(collectedMethods, columns=colNames)\n",
    "        #df.to_pickle(outputFilePath, compression='gzip')\n",
    "        df.to_parquet(outputFilePath)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def Inst2ID(instruction):\n",
    "    global InstructionDict_df\n",
    "\n",
    "    className = instruction.split('->')[0].split('$')[0]\n",
    "    if instruction in InstructionDict_df.index:\n",
    "        return InstructionDict_df[instruction]\n",
    "    elif className in InstructionDict_df.index:\n",
    "        return InstructionDict_df[className]\n",
    "    else: \n",
    "        return None\n",
    "\n",
    "def parseInstruction(instruction : str) -> list:\n",
    "    opcode = ''\n",
    "    args = []\n",
    "\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    instParts = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')\n",
    "    meta = ''\n",
    "\n",
    "    if len(instParts) > 1:\n",
    "        meta      = instParts[-1]\n",
    "        instParts = instParts[0]\n",
    "        meta = meta.split('@')[0]\n",
    "    else:\n",
    "        instParts = instParts[0]    \n",
    "    instParts = instParts.split(' ')\n",
    "    #instParts = [item for item in instParts if item != '']\n",
    "    opcode = instParts[0]\n",
    "    args = []\n",
    "\n",
    "    # TODO proto meta \n",
    "    if len(instParts) > 1:\n",
    "        args = ' '.join(instParts[1:]).split(', ')\n",
    "        if args[-1][0] == '\"':\n",
    "            args[-1] = 'string'\n",
    "            \n",
    "        elif args[-1][0] == '#':\n",
    "            args[-1] = args[-1].split()[0][1:]\n",
    "            \n",
    "        elif args[-1][0] == '0':\n",
    "            args[-1] = 'hex'\n",
    "            \n",
    "        elif meta == 'field':\n",
    "            fields = args[-1].split(':')\n",
    "            if len(fields) > 1:\n",
    "                args[-1] = fields[1].replace(';', '')\n",
    "                if args[-1][0] != 'L' or (len(args[-1].split('/')[0]) == 2):\n",
    "                    args[-1] = 'field'\n",
    "            else:\n",
    "                args[-1] = 'field'\n",
    "                \n",
    "        elif meta == 'type':\n",
    "            args[-1] = args[-1].replace(';', '')\n",
    "            if (args[-1][0] != 'L') or (len(args[-1].split('/')[0]) == 2):\n",
    "                args[-1] = 'type'\n",
    "                \n",
    "        elif meta == 'method':\n",
    "            args[-1] = args[-1].replace(';.', '->')\n",
    "            methodParts = args[-1].split(':')\n",
    "            methodCall = methodParts[0]\n",
    "            if len(methodCall.split('/')[0]) == 2:\n",
    "                methodCall = 'class.local'\n",
    "            if len(methodParts) > 1:\n",
    "                methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "                methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "            else:\n",
    "                methodArgs = []\n",
    "\n",
    "            mtdSplit = methodCall.split('->')\n",
    "            if len(mtdSplit) > 1:\n",
    "                methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "\n",
    "            args[-1] = methodCall\n",
    "\n",
    "            args.extend(methodArgs)\n",
    "        else:\n",
    "            args = [item for item in args if len(item) > 1 and item[0] == 'v']\n",
    "        \n",
    "    args = [opcode] + args\n",
    "    args = [Inst2ID(argo) for argo in args]\n",
    "    argsIDs = np.array([argo for argo in args if argo != None], dtype='uint32')\n",
    "            \n",
    "    return argsIDs\n",
    "\n",
    "def parseMethodCallArguments(instruction : str) -> list:\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    method = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')[0].split(' ')[-1]\n",
    "\n",
    "    method = method.replace(';.', '->')\n",
    "    methodParts = method.split(':')\n",
    "    methodCall = methodParts[0]\n",
    "    if len(methodCall.split('/')[0]) == 2:\n",
    "        methodCall = 'class.local####'\n",
    "        \n",
    "    if len(methodParts) > 1:\n",
    "        methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "        methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "    else:\n",
    "        methodArgs = []\n",
    "        \n",
    "    mtdSplit = methodCall.split('->')\n",
    "    if len(mtdSplit) > 1:\n",
    "        methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "                    \n",
    "    args = [methodCall] + methodArgs\n",
    "    args = [Inst2ID(argo) for argo in args]\n",
    "    argsIDs = np.array([argo for argo in args if argo != None], dtype='uint32')\n",
    "    \n",
    "    return argsIDs\n",
    "\n",
    "def parseMethodCall(instruction : str) -> str:\n",
    "    instruction = instruction.split(': ')[-1]\n",
    "    method = instruction.replace('{', '').replace('}', '').replace('[', '').strip().split(' // ')[0].split(' ')[-1]\n",
    "\n",
    "    method = method.replace(';.', '->')\n",
    "    methodParts = method.split(':')\n",
    "    methodCall = methodParts[0]\n",
    "    if len(methodCall.split('/')[0]) == 2:\n",
    "        methodCall = 'class.local'\n",
    "        \n",
    "    if len(methodParts) > 1:\n",
    "        methodArgs = methodParts[1].replace('(', '').replace(')', '').split(';')\n",
    "        methodArgs = [item for item in methodArgs if len(item) != 0 and item[0] == 'L']\n",
    "    else:\n",
    "        methodArgs = []\n",
    "        \n",
    "    mtdSplit = methodCall.split('->')\n",
    "    if len(mtdSplit) > 1:\n",
    "        methodCall = mtdSplit[0].split('$')[0] + '->' + mtdSplit[1].split('$')[0]\n",
    "        \n",
    "    methodID = Inst2ID(methodCall)\n",
    "    \n",
    "    return methodID\n",
    "\n",
    "def parseDex(FileName : str) -> list:\n",
    "    global outputRoot\n",
    "    global inputRoot\n",
    "    \n",
    "    outputFilePath = outputRoot + FileName\n",
    "    inputFilePath  = inputRoot  + FileName\n",
    "\n",
    "    dex = subprocess.run(['dexdump', '-d', inputFilePath], stdout=subprocess.PIPE).stdout.decode(encoding=\"ISO-8859-1\")\n",
    "    condidatClasses = re.split(\"Class descriptor  : '\", dex)[1:]\n",
    "\n",
    "    collectedMethods = []\n",
    "\n",
    "    for currentClass in condidatClasses:\n",
    "        if currentClass.split('$')[0] not in InstructionDict_df.index:\n",
    "            className = currentClass.split('\\n')[0][1:-2]\n",
    "            currentCondidatMethods = re.split('    #\\d', currentClass)\n",
    "            for method in currentCondidatMethods:\n",
    "                if method != '':\n",
    "                    Instructions = [item for item in method.split('\\n') if '|' in item]\n",
    "                    if len(Instructions) != 0:\n",
    "                        methodMeta = Instructions[0].split()[-1]\n",
    "                        Instructions = Instructions[1:]\n",
    "\n",
    "                        functionOpcodes            = ''.join([re.split('\\: |\\|', instruction)[1].strip()  for instruction in Instructions])\n",
    "                        functionOpcodes            = re.sub('[^a-f0-9]+', '', functionOpcodes)\n",
    "                        functionOpcodes            = np.array([int(functionOpcodes[idx:idx+2], 16) for idx in range(int(len(functionOpcodes) / 2))], dtype='uint8')\n",
    "\n",
    "                        #functionInstructions       = np.concatenate([parseInstruction(line)         for line in Instructions] + [np.array([], dtype='uint16')])\n",
    "                        \n",
    "                        functionMethodCallsArgs    = np.concatenate([parseMethodCallArguments(line) for line in Instructions if ('method@' in line)] + [np.array([], dtype='uint32')])\n",
    "                        \n",
    "                        functionMethodCalls        = [parseMethodCall(line)          for line in Instructions if ('method@' in line)]\n",
    "                        functionMethodCalls        = np.array([inst for inst in functionMethodCalls if inst != None], dtype='uint32')\n",
    "                        \n",
    "                        collectedMethods.append((className, methodMeta, functionOpcodes, functionMethodCallsArgs, functionMethodCalls, functionInstructions)) #, Instructions))\n",
    "\n",
    "    if len(collectedMethods) > 1:\n",
    "        colNames = ['className', 'methodMeta', 'functionOpcodes', \n",
    "                    'functionMethodCallsArgs', 'functionMethodCalls', \n",
    "                     'functionInstructions'] #, 'Instructions']\n",
    "        df = pd.DataFrame(collectedMethods, columns=colNames)\n",
    "        df['className'] = pd.factorize(df.className)[0]\n",
    "        df['methodMeta'] = pd.factorize(df.methodMeta)[0]\n",
    "\n",
    "        df.to_parquet(outputFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VocabDict = pd.read_csv('dataset/InstructionDict.csv', index_col=0, names=['ID'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ClassesVocabDict = pd.read_csv('dataset/ClassesVocabDict.csv', index_col=0)\n",
    "VocabDict = ClassesVocabDict.iloc[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "minizoo_df = pd.read_csv('dataset/minizoo_df.csv')\n",
    "#minizoo_df = minizoo_df.sample(5000, random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=40)\n",
    "\n",
    "outputRoot = '/ws/papers/active/petadroid/code/output/vocab64k/'\n",
    "inputRoot  = '/ws/mnt/habouch/datasets/zoo_dataset/'\n",
    "\n",
    "#fileNames     = [fileName.strip() for fileName in open('dataset/minizoo_df.txt', 'r').readlines()]\n",
    "fileNames     = minizoo_df.sha256.to_list()\n",
    "\n",
    "doneFileNames = [item.split('/')[-1] for item in glob.glob(outputRoot + '*')]\n",
    "todoFileNames = np.array(list(set(fileNames).difference(set(doneFileNames))))\n",
    "print(len(todoFileNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypool.map(parseDex, todoFileNames)\n",
    "mypool.close();\n",
    "mypool.join();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "outputRoot = '/ws/papers/active/petadroid/code/output/dataframes/'\n",
    "doneFileNames = [item.split('/')[-1] for item in glob.glob(outputRoot + '*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArrayList(FileNames: list) -> list:\n",
    "    arrayList = []\n",
    "    for fileName in FileNames:\n",
    "        inputFilePath = outputRoot + fileName\n",
    "        arrayList.append((fileName, np.array([item.astype('uint8') for item in  pd.read_pickle(inputFilePath, compression='gzip').functionOpcodes.values])))\n",
    "    return arrayList\n",
    "\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=50)\n",
    "FileNameGroups = np.array_split(doneFileNames, 50)\n",
    "result = mypool.map(getArrayList, FileNameGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFunctionInstructionsVocabular(FileNameList : list) -> Counter:\n",
    "    vocabularCounter = Counter()\n",
    "    for FileName in FileNameList:\n",
    "        inputFilePath    = outputRoot + FileName\n",
    "        vocabularCounter += Counter((' '.join(pd.read_pickle(inputFilePath, compression='gzip').functionInstructions)).split())\n",
    "        \n",
    "    return vocabularCounter\n",
    "\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=50)\n",
    "FileNameGroups = np.array_split(doneFileNames, 50)\n",
    "result = mypool.map(buildFunctionInstructionsVocabular, FileNameGroups)\n",
    "\n",
    "instuctionsDict = Counter()\n",
    "for cnt in result:\n",
    "    instuctionsDict += cnt\n",
    "\n",
    "s = pd.DataFrame(list(instuctionsDict.items()), columns=['instruction', 'count'])\n",
    "s.sort_values('count', inplace=True, ascending=False)\n",
    "s.reset_index(drop=True, inplace=True)\n",
    "s.to_csv('dataset/functionInstructionsVocabDict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFunctionMethodCallsVocabular(FileNameList : list) -> Counter:\n",
    "    vocabularCounter = Counter()\n",
    "    for FileName in FileNameList:\n",
    "        inputFilePath    = outputRoot + FileName\n",
    "        vocabularCounter += Counter((' '.join(pd.read_pickle(inputFilePath, compression='gzip').functionMethodCalls)).split())\n",
    "        \n",
    "    return vocabularCounter\n",
    "\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=50)\n",
    "FileNameGroups = np.array_split(doneFileNames, 50)\n",
    "result = mypool.map(buildFunctionMethodCallsVocabular, FileNameGroups)\n",
    "\n",
    "instuctionsDict = Counter()\n",
    "for cnt in result:\n",
    "    instuctionsDict += cnt\n",
    "\n",
    "s = pd.DataFrame(list(instuctionsDict.items()), columns=['instruction', 'count'])\n",
    "s.sort_values('count', inplace=True, ascending=False)\n",
    "s.reset_index(drop=True, inplace=True)\n",
    "s.to_csv('dataset/functionMethodCallsVocabDict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFunctionMethodCallsArgsVocabular(FileNameList : list) -> Counter:\n",
    "    vocabularCounter = Counter()\n",
    "    for FileName in FileNameList:\n",
    "        inputFilePath    = outputRoot + FileName\n",
    "        vocabularCounter += Counter((' '.join(pd.read_pickle(inputFilePath, compression='gzip').functionMethodCallsArgs)).split())\n",
    "        \n",
    "    return vocabularCounter\n",
    "\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=50)\n",
    "FileNameGroups = np.array_split(doneFileNames, 50)\n",
    "result = mypool.map(buildFunctionMethodCallsArgsVocabular, FileNameGroups)\n",
    "\n",
    "instuctionsDict = Counter()\n",
    "for cnt in result:\n",
    "    instuctionsDict += cnt\n",
    "\n",
    "s = pd.DataFrame(list(instuctionsDict.items()), columns=['instruction', 'count'])\n",
    "s.sort_values('count', inplace=True, ascending=False)\n",
    "s.reset_index(drop=True, inplace=True)\n",
    "s.to_csv('dataset/functionMethodCallsArgsVocabDict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def builldInstructionDictionary(FileName):\n",
    "    global hexContentRoot\n",
    "    \n",
    "    outputFrameFilePath = hexContentRoot + 'frame/'   + FileName\n",
    "    outputContentFilePath = hexContentRoot + 'content/' + FileName\n",
    "\n",
    "    inputFilePath = outputRoot + FileName\n",
    "    df = pd.DataFrame([item[:3] for item in pickle.loads(gzip.open(inputFilePath, 'rb').read())], columns=['className', 'methodName', 'hexContent'])\n",
    "    df['hexContent'] = df.hexContent.apply(lambda x: ''.join(x.split()))\n",
    "    hexContent = ''.join(df.hexContent)\n",
    "    pd.to_msgpack(outputContentFilePath, hexContent, compress='zlib')\n",
    "    pd.to_msgpack(outputFrameFilePath, df, compress='zlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import gzip\n",
    "from multiprocessing import Pool\n",
    "mypool = Pool(processes=50)\n",
    "\n",
    "outputRoot = '/ws/papers/active/petadroid/code/output/dataframes/'\n",
    "#hexContentRoot  = '/ws/papers/active/petadroid_ws/output/hexContent/'\n",
    "doneFileNames = [item.split('/')[-1] for item in glob.glob(outputRoot + '*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doneFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypool.map(builldInstructionDictionary, doneFileNames)\n",
    "mypool.join();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_df = pd.read_csv('dataset/functionMethodCallsVocabDict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### level1 = method_df.instruction.str.split('/').apply(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "level2 = method_df.instruction.str.split('/').apply(lambda x: '.'.join(x[:2])).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysciws",
   "language": "python",
   "name": "sciws"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
